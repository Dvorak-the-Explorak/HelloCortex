import feedparser
from urllib.request import urlopen, Request
from itertools import takewhile
import sys
import codecs
import json

if sys.stdout.encoding != 'UTF-8':
  sys.stdout = codecs.getwriter('UTF-8')(sys.stdout.buffer, 'strict')


def parseHelloInternet(verbose=False):
	url = "http://www.hellointernet.fm/podcast?format=rss"
	url_archive = "https://raw.githubusercontent.com/yottalogical/hello-internet-archive/master/HelloInternetArchive.rss"
	
	feed = feedparser.parse(url)
	feed_archive = feedparser.parse(url_archive)
	first_archive_id = feed_archive.entries[0]['id']

	combined_entries = list(takewhile(lambda x: x['id'] != first_archive_id, feed.entries)) + feed_archive.entries

	ids = [item['id'] for item in feed.entries]
	ids_archive = [item['id'] for item in feed_archive.entries]
	ids_all = list(set(ids+ids_archive))
	overlap = len(ids) + len(ids_archive) - len(ids_all)

	if verbose:
		print(f"Overlap episodes: {overlap}")

		print("\tCombined feed:")
		for item in combined_entries:
			print(f"{item['title']}")

	feed.entries = combined_entries
	return feed

def parseCortex(verbose=False):
	url = "https://www.relay.fm/cortex/feed"
	feed = feedparser.parse(url)
	if verbose:
		for item in feed.entries:
			print(f"{item['title']}")

	return feed



def parseCombined(verbose=False):
	def prefix_title(prefix, item):
		result = item.copy()
		result['title'] = prefix + result['title']
		return result

	next_verbose = max(verbose-1, 0)

	hi_feed = parseHelloInternet(next_verbose)
	cortex_feed = parseCortex(next_verbose)

	if hi_feed['version'] != cortex_feed['version']:
		print("WARNING: RSS feed versions don't match!")
		print(f"HI rss version: {hi_feed['version']}")
		print(f"CX rss version: {cortex_feed['version']}")

	# Hello internet already has "H.I." at the start of the title
	hi_labeled = [item for item in hi_feed.entries]
	# Add "CRTX " to the start of each cortex title
	cortex_labeled = [prefix_title('CRTX ', item) for item in cortex_feed.entries]

	merged_entries = hi_labeled + cortex_labeled
	merged_entries.sort(key=lambda x: x['published_parsed'])

	if verbose:
		print("\tCombined feed:")
		for item in merged_entries:
			print(f"{item['title']} {item['published']}")



	result = hi_feed.copy()
	result['feed']['title'] = "Hello Cortex"
	result['feed']['title_detail']['value'] = "Hello Cortex"
	result['feed']['links'] += cortex_feed['feed']['links']
	result['feed']['link'] = "C:/hellocortex.html"
	if result['feed']['updated_parsed'] < cortex_feed['feed']['updated_parsed']:
		result['feed']['updated'] = cortex_feed['feed']['updated']
		result['feed']['updated_parsed'] = cortex_feed['feed']['updated_parsed']
	result['feed'].pop('generator', None)
	result['feed'].pop('generator_detail', None)
	# result['feed']['generator'] += " AND " + cortex_feed['feed']['generator']
	# result['feed']['generator_detail']['name'] = result['feed']['generator']
	result['feed']['authors'] += cortex_feed['feed']['authors'] 
	result['feed']['subtitle'] = f"A combination of 'Hello Internet' and 'Cortex'"
	result['feed']['subtitle_detail']['value'] = f"A combination of 'Hello Internet' ({result['feed']['subtitle']}) and 'Cortex' ({cortex_feed['feed']['subtitle']})"
	result['feed']['tags'] += cortex_feed['feed']['tags']
	result['entries'] = merged_entries

	return result



def unparse(feed):
	from html import escape
	from queue import LifoQueue
	tails = LifoQueue()

	def strbool(b):
		return 'true' if b else 'false'

	def start_tag(tag, extra=""):
		nonlocal result, tails
		if len(extra):
			result += f"<{tag} {extra}>"
		else:
			result += f"<{tag}>"
		tails.put(f"</{tag}>")
	def end_tag():
		nonlocal result, tails
		result += tails.get()

	def end_all_tags():
		nonlocal result, tails
		while not tails.empty():
			result += tails.get()


	def add_simple(name, parsedname=None, cdata=False, extra=""):
		nonlocal result
		if parsedname is None:
			parsedname = name
		start_tag(name, extra)
		if cdata:
			result += f"<![CDATA[{feed['feed'][parsedname]}]]>"
		else:
			result += escape(feed['feed'][parsedname])
		end_tag()

	def add_simple_entry(name, parsedname=None, cdata=False, extra="", silentfail=False):
		nonlocal result, entry


		if parsedname is None:
			parsedname = name
		if parsedname not in entry.keys():
			return 

		start_tag(name, extra)
		if cdata:
			result += f"<![CDATA[{entry[parsedname]}]]>"
		else:
			result += escape(entry[parsedname])
		end_tag()

	result = '''<?xml version="1.0" encoding="UTF-8"?>
<!-- Generated by a hacky python combinator -->
<rss xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:wfw="http://wellformedweb.org/CommentAPI/" xmlns:itunes="http://www.itunes.com/dtds/podcast-1.0.dtd" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://www.rssboard.org/media-rss" version="2.0">'''
	tails.put('</rss>')

	start_tag("channel")
	add_simple('title')
	add_simple('link')
	try:
		add_simple('lastBuildDate', 'updated')
	except:
		add_simple('lastBuildDate', 'published')
	add_simple('language')
	# add_simple('generator')
	add_simple('itunes:author', 'author')
	add_simple('itunes:subtitle', 'subtitle')

	start_tag('itunes:explicit')
	result += 'yes' if feed['feed']['itunes_explicit'] else 'no'
	end_tag()

	start_tag("itunes:owner")
	add_simple("itunes:name", 'author')
	start_tag('itunes:email')
	result += escape(feed['feed']['author_detail']['email'])
	end_tag()
	end_tag()
	result += '<itunes:category text="Education"/>'
	result += '<itunes:type>episodic</itunes:type>'

	val = escape(feed['feed']['image']['href'])
	result += f'<itunes:image href="{val}"/>'


	add_simple('description', cdata=True)



	# print("LINKS")
	# for item in feed['entries'][0]['links']:
	# 	print(f"\t{item}")


	for entry in feed['entries']:
		start_tag('item')
		add_simple_entry('title')
		add_simple_entry('dc:creator', 'author')
		add_simple_entry('pubdate', 'published')
			
		add_simple_entry('link')
		extra = f'isPermaLink="{strbool(entry["guidislink"])}"'
		add_simple_entry('guid', 'id', extra=extra)
		if 'description' in entry.keys():
			add_simple_entry('description', cdata=True)
		else:
			add_simple_entry('description', 'summary', cdata=True)
		add_simple_entry('itunes:author', 'author')

		start_tag('itunes:explicit')
		result += strbool(entry['itunes_explicit'])
		end_tag()

		add_simple_entry('itunes:duration', 'itunes_duration', silentfail=True)
		add_simple_entry('itunes:author', 'author')
		result += f'<itunes:image href="{escape(entry["image"]["href"])}"/>'

		add_simple_entry('itunes:episode', 'itunes_episode', silentfail=True)
		add_simple_entry('itunes:title', 'itunes_title', silentfail=True)

		result += '<itunes:episodeType>full</itunes:episodeType>'

		#TODO find the one that's actually 'type': 'audio/mp3'
		mp3_url = escape(entry['links'][0]['href'])
		result += f'<enclosure url="{mp3_url}" type="audio/mpeg"/>'
		result += f'<media:content url="{mp3_url}" type="audio/mpeg" isDefault="true" medium="audio">'
		result += f'<media:title type="plain">{escape(entry["title"])}</media:title>'
		result += '</media:content>'
		result += f'<enclosure url="{mp3_url}" type="audio/mpeg"/>'

		end_tag()#item

	end_all_tags()
	return result

def levenshteinDistance(s1, s2):
    if len(s1) > len(s2):
        s1, s2 = s2, s1

    distances = range(len(s1) + 1)
    for i2, c2 in enumerate(s2):
        distances_ = [i2+1]
        for i1, c1 in enumerate(s1):
            if c1 == c2:
                distances_.append(distances[i1])
            else:
                distances_.append(1 + min((distances[i1], distances[i1 + 1], distances_[-1])))
        distances = distances_
    return distances[-1]


def testunparse():
	url = "https://www.relay.fm/cortex/feed"
	request = Request(url)
	request.add_header('User-Agent', 'Mozilla/5.0')
	raw_xml = urlopen(request).read().decode('utf-8')
	with open("cortex_raw.xml", 'w', encoding='utf-8') as outf:
		outf.write(raw_xml)

		
	feed = feedparser.parse(url)
	unparsed = unparse(feed)
	with open("cortex_unparsed.xml", 'w', encoding='utf-8') as outf:
		outf.write(unparsed)





def createHelloCortex():
	print("Parsing feeds... ", end='')
	feed = parseCombined()
	print("Done.")

	print("Constructing XML... ", end='')
	result = unparse(feed)
	print("Done.")


	if result:
		with open("hello_cortex.xml", 'w', encoding="utf-8") as outf:
			outf.write(result)



createHelloCortex()